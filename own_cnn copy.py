{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c5a31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pylint: disable=undefined-variable\n",
    "#pylint: disable=line-too-long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db5b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b12c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import (\n",
    "    FILENAME,\n",
    "    CHECKPOINT_PATH,\n",
    "    LEARNING_RATE,\n",
    "    BATCH_SIZE,\n",
    "    WIN_LEN,\n",
    "    LOAD_MODEL,\n",
    ")\n",
    "\n",
    "# Set DEVICE\n",
    "DEVICE: torch.device = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ff88d",
   "metadata": {},
   "source": [
    "### Custom 2D Convolution Layer (`CustomConv2d`)\n",
    "\n",
    "Eine 2D-Convolution lässt eine Menge lernbarer Kernel über eine Eingabe gleiten und\n",
    "berechnet an jeder Position ein Skalarprodukt. Das Ergebnis ist eine neue Menge an\n",
    "Feature Maps, wobei jede ein anderes lokales Muster erkennt wie z.B. charakteristische\n",
    "Verläufe in den Sensordaten.\n",
    "\n",
    "Anstatt PyTorchs `nn.Conv2d` zu verwenden, wird hier `torch.autograd.Function` genutzt,\n",
    "um sowohl Forward- als auch Backward-Pass explizit zu implementieren. Das macht jeden\n",
    "Schritt der Gradientenberechnung sichtbar und nachvollziehbar.\n",
    "\n",
    "---\n",
    "\n",
    "### Forward Pass\n",
    "\n",
    "Die Eingabe hat die Form\n",
    "\n",
    "$$X \\in \\mathbb{R}^{B \\times C_{\\text{in}} \\times H \\times W}$$\n",
    "\n",
    "mit $B$ Samples im Batch, $C_{\\text{in}}$ Input-Channels und räumlicher Größe $H \\times\n",
    "W$. Der Layer hat $C_{\\text{out}}$ Kernel der Form $C_{\\text{in}} \\times K_h \\times\n",
    "K_w$, sowie einen Bias $b \\in \\mathbb{R}^{C_{\\text{out}}}$.\n",
    "\n",
    "---\n",
    "\n",
    "#### Schritt 1 — `im2col`\n",
    "\n",
    "Anstatt das Sliding Window direkt zu implementieren, wird die Eingabe zunächst mit `F.unfold` in eine Spaltenmatrix umgeformt:\n",
    "\n",
    "$$X_{\\text{col}} \\in \\mathbb{R}^{B \\times (C_{\\text{in}} \\cdot K_h \\cdot K_w) \\times L},\n",
    "\\quad L = H_{\\text{out}} \\cdot W_{\\text{out}}$$\n",
    "\n",
    "Jede Spalte in $X_{\\text{col}}$ ist ein geflachter (flatten) Ausschnitt der Eingabe, auf\n",
    "dem der Kernel an dieser Position liegt.\n",
    "\n",
    "---\n",
    "\n",
    "#### Schritt 2 — Gewichte flatten\n",
    "\n",
    "Die Kernel werden in eine 2D-Matrix umgeformt, sodass die Cross-Correlation als\n",
    "Matrixmultiplikation berechnet werden kann:\n",
    "\n",
    "$$W_{\\text{flat}} \\in \\mathbb{R}^{C_{\\text{out}} \\times (C_{\\text{in}} \\cdot K_h \\cdot K_w)}$$\n",
    "\n",
    "Hierbei ist jede Zeile eine Feature Map.\n",
    "\n",
    "---\n",
    "\n",
    "#### Schritt 3 — Matrixmultiplikation\n",
    "\n",
    "$$Y_{\\text{flat}} = W_{\\text{flat}} \\cdot X_{\\text{col}} + b$$\n",
    "\n",
    "Der Bias wird über alle $L$ Positionen gebroadcastet. Das Ergebnis wird umgeformt zu\n",
    "\n",
    "$$Y \\in \\mathbb{R}^{B \\times C_{\\text{out}} \\times H_{\\text{out}} \\times W_{\\text{out}}}$$\n",
    "\n",
    "wobei die räumliche Ausgabegröße aus Stride $s$ und Padding $p$ folgt:\n",
    "\n",
    "$$H_{\\text{out}} = \\frac{H + 2p - K_h}{s} + 1, \\qquad W_{\\text{out}} = \\frac{W + 2p - K_w}{s} + 1$$\n",
    "\n",
    "---\n",
    "\n",
    "### Backward Pass\n",
    "\n",
    "Gegeben sei $\\frac{\\partial \\mathcal{L}}{\\partial Y} \\in \\mathbb{R}^{B \\times C_{\\text{out}} \\times H_{\\text{out}} \\times W_{\\text{out}}}$ aus der nachfolgenden Schicht.\n",
    "Daraus können drei Gradienten berechnet werden:\n",
    "\n",
    "#### Gradient der Gewichte\n",
    "\n",
    "Der eingehende Gradienten auf $(B, C_{\\text{out}}, L)$ muss umgeformt und über den Batch\n",
    "aufsummieren werden:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial W} = \\sum_{b=1}^{B} \\frac{\\partial \\mathcal{L}}{\\partial Y_{\\text{flat}}}[b] \\cdot X_{\\text{col}}[b]^\\top \\;\\in \\mathbb{R}^{C_{\\text{out}} \\times C_{\\text{in}} \\times K_h \\times K_w}$$\n",
    "\n",
    "#### Gradient des Bias\n",
    "\n",
    "Entspricht der Summe über Batch- und räumliche Dimensionen:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial b} = \\sum_{b,i,j} \\frac{\\partial \\mathcal{L}}{\\partial Y_{b,:,i,j}} \\;\\in \\mathbb{R}^{C_{\\text{out}}}$$\n",
    "\n",
    "#### Gradient des Inputs\n",
    "\n",
    "Die transponierte Gewichtsmatrix wird mit dem geflachten (flatten) Gradienten\n",
    "multipliziert und anschließend mit `F.fold` (die Umkehroperation von `F.unfold`) wieder\n",
    "in die ursprüngliche Eingabeform zurück transformiert:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial X_{\\text{col}}} = W_{\\text{flat}}^\\top \\cdot \\frac{\\partial \\mathcal{L}}{\\partial Y_{\\text{flat}}} \\;\\xrightarrow{\\text{fold}}\\; \\frac{\\partial \\mathcal{L}}{\\partial X} \\in \\mathbb{R}^{B \\times C_{\\text{in}} \\times H \\times W}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eea91108",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(\n",
    "        ctx, x: Tensor, weight: Tensor, bias: Tensor, stride: int, padding: int\n",
    "    ) -> Tensor:\n",
    "\n",
    "        B, C_in, H, W = x.shape\n",
    "        C_out, _, K_h, K_w = weight.shape\n",
    "        # C_out: number of kernels, _: depth\n",
    "\n",
    "        # im2col method: matrix multiplication for convolution\n",
    "        # unfold input matrix into columns for each sliding window\n",
    "        x_col: Tensor = F.unfold(\n",
    "            x, kernel_size=(K_h, K_w), padding=padding, stride=stride\n",
    "        )\n",
    "        # x_col: (B, C_in*K_h*K_w, L)\n",
    "        # L = H_out * W_out\n",
    "\n",
    "        # Flatten weight for matrix multiplication\n",
    "        weight_flat: Tensor = weight.view(C_out, C_in * K_h * K_w)\n",
    "        # (C_out, C_in*K_h*K_w)\n",
    "\n",
    "        # Matrix multiplication\n",
    "        out: Tensor = weight_flat @ x_col\n",
    "        # out: (C_out, C_in*K_h*K_w) @ (C_in*K_h*K_w, L) -> (C_out, L)\n",
    "        # with Batch Dimension: (B, C_out, L)\n",
    "\n",
    "        if bias is not None:\n",
    "            out: Tensor = out + bias.view(1, C_out, 1)\n",
    "\n",
    "        # Output spatial size\n",
    "        H_out: int = (H + 2 * padding - K_h) // stride + 1\n",
    "        W_out: int = (W + 2 * padding - K_w) // stride + 1\n",
    "\n",
    "        out: Tensor = out.view(B, C_out, H_out, W_out)\n",
    "\n",
    "        # Save for backward-Pass\n",
    "        ctx.save_for_backward(x, weight, bias, x_col)\n",
    "        ctx.stride = stride\n",
    "        ctx.padding = padding\n",
    "        ctx.kernel_size = (K_h, K_w)\n",
    "\n",
    "        return out\n",
    "\n",
    "    # C_out: num of kernels + depth of output\n",
    "    # C_in: depth of input + depth of kernel\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(\n",
    "        ctx, grad_output: Tensor\n",
    "    ) -> tuple[Tensor, Tensor, Tensor, None, None]:\n",
    "\n",
    "        x, weight, bias, x_col = ctx.saved_tensors\n",
    "        stride: int = ctx.stride\n",
    "        padding: int = ctx.padding\n",
    "        K_h, K_w = ctx.kernel_size\n",
    "\n",
    "        B, C_out, _, _ = grad_output.shape\n",
    "        C_out, C_in, _, _ = weight.shape\n",
    "\n",
    "        grad_output_flat: Tensor = grad_output.view(B, C_out, -1)\n",
    "        # (B, C_out, L) mit L: H_out x W_out\n",
    "\n",
    "        weight_flat: Tensor = weight.view(C_out, -1)\n",
    "\n",
    "        # Gradient Weight Calculation\n",
    "        grad_weight: Tensor = torch.zeros_like(weight)\n",
    "        for b in range(B):\n",
    "            grad_weight += (grad_output_flat[b] @ x_col[b].T).view_as(weight)\n",
    "\n",
    "        # Gradient Bias Calculation\n",
    "        grad_bias = None\n",
    "        if bias is not None:\n",
    "            grad_bias: Tensor = grad_output.sum(dim=(0, 2, 3))\n",
    "        # sum over batch, H_out and W_out dimensions -> (C_out,)\n",
    "\n",
    "        # Gradient Input Calculation\n",
    "        grad_input_col: Tensor = weight_flat.T @ grad_output_flat\n",
    "        # (B, C_in*K*K, L)\n",
    "\n",
    "        # fold back to input shape\n",
    "        grad_input: Tensor = F.fold(\n",
    "            grad_input_col,\n",
    "            output_size=(x.shape[2], x.shape[3]),\n",
    "            kernel_size=(K_h, K_w),\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "        )\n",
    "        # grad_input: (B, C_in, H, W)\n",
    "\n",
    "        return grad_input, grad_weight, grad_bias, None, None\n",
    "\n",
    "\n",
    "class CustomConv2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        stride: int = 1,\n",
    "        padding: int = 1,\n",
    "        bias: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        k_h = k_w = kernel_size\n",
    "        # random Parameterinitialisierung mit der He-Initialisierung\n",
    "        # mit der Dimension: out_channels x in_channels x k_h x k_w\n",
    "        # 64 Feature Maps mit je 64 Kernels à 3x3\n",
    "        scale: float = (2 / (in_channels * k_h * k_w)) ** 0.5\n",
    "        self.weight: nn.Parameter = nn.Parameter(\n",
    "            torch.randn(out_channels, in_channels, k_h, k_w) * scale\n",
    "        )\n",
    "\n",
    "        # Vektor mit Länge out_channels, da jeder Kernel einen Bias hat\n",
    "        self.bias: nn.Parameter = (\n",
    "            nn.Parameter(torch.zeros(out_channels)) if bias else None\n",
    "        )\n",
    "\n",
    "        self.stride: int = stride\n",
    "        self.padding: int = padding\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return Conv2dFunction.apply(\n",
    "            x, self.weight, self.bias, self.stride, self.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb34ae",
   "metadata": {},
   "source": [
    "#### Activation Function: Leaky ReLU\n",
    "\n",
    "Aktivierungsfunktionen führen die Nicht-Linearität ein, die neuronale Netze brauchen um komplexe Muster zu lernen. Ohne sie würde das gesamte Netz, egal wie viele Schichten, auf eine einzige lineare Abbildung Y = WX + b reduziert werden. Sie werden elementweise auf den Output jedes Neurons angewendet.\n",
    "\n",
    "- Definition: $$f(x)=\n",
    "\\begin{cases}\n",
    "x & x > 0, \\\\\n",
    "\\alpha x & x \\leq 0,\n",
    "\\end{cases}$$\n",
    "- Ableitung: $$\\frac{\\partial f}{\\partial x} =\n",
    "\\begin{cases}\n",
    "1 & x > 0, \\\\\n",
    "\\alpha & x \\leq 0.\n",
    "\\end{cases}$$\n",
    "\n",
    "Leaky ReLU gibt negativen Werten einen kleinen, aber nicht-null Gradienten (α typischerweise zwischen 1e-3 und 0.1, hier: 0.01). Das verhindert das sogenannte \"Dying ReLU\"-Problem, bei dem Neuronen dauerhaft inaktiv werden und nichts mehr zum Lernprozess beitragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77252afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakyReLUFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x: Tensor, alpha: float) -> Tensor:\n",
    "        ctx.alpha = alpha\n",
    "        ctx.save_for_backward(x)\n",
    "        return torch.where(x > 0, x, alpha * x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: Tensor) -> tuple[Tensor, None]:\n",
    "        (x,) = ctx.saved_tensors\n",
    "        alpha = ctx.alpha\n",
    "        grad_input = torch.where(x > 0, grad_output, grad_output * alpha)\n",
    "        return grad_input, None\n",
    "\n",
    "\n",
    "class CustomLeakyReLU(nn.Module):\n",
    "    def __init__(self, alpha: float = 0.01) -> None:\n",
    "        super().__init__()\n",
    "        if alpha < 0:\n",
    "            raise ValueError(\"alpha must be non-negative\")\n",
    "        self.alpha: float = alpha\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return LeakyReLUFunction.apply(x, self.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b6db7",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "\n",
    "Nach dem Adaptive Average Pooling hat jeder Channel nur noch einen einzigen Skalar. Der Tensor hat also die Form `(B, 64, 1, 1)`. Der Flatten Layer klappt die beiden räumlichen Dimensionen `1x1` zusammen, sodass ein Vektor der Form `(B, 64)` entsteht, ein Wert pro Channel pro Sample. Genau das erwartet der nachfolgende `CustomDense(64, 64)` als Eingabe.\n",
    "\n",
    "Der Flatten Layer hat keine lernbaren Parameter, er ist eine reine Umformung.\n",
    "\n",
    "---\n",
    "\n",
    "#### Forward\n",
    "\n",
    "$$\n",
    "X \\in \\mathbb{R}^{B \\times 64 \\times 1 \\times 1}\n",
    "\\;\\xrightarrow{\\text{reshape}}\\;\n",
    "Y \\in \\mathbb{R}^{B \\times 64}\n",
    "$$\n",
    "\n",
    "Da nach dem Pooling $H = W = 1$ gilt, ergibt sich $C \\cdot H \\cdot W = 64 \\cdot 1 \\cdot 1 = 64$.\n",
    "\n",
    "---\n",
    "\n",
    "#### Backward\n",
    "\n",
    "Der Gradient aus dem Dense Layer hat die Form `(B, 64)` und muss lediglich wieder in `(B, 64, 1, 1)` umgeformt werden:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial X} = \\mathrm{reshape}\\!\\left(\\frac{\\partial \\mathcal{L}}{\\partial Y},\\; B \\times 64 \\times 1 \\times 1\\right)\n",
    "$$\n",
    "\n",
    "Das entspricht direkt `grad_output.reshape(x.shape)` in `FlattenLayer.backward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fd5430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x: Tensor) -> Tensor:\n",
    "        ctx.save_for_backward(x)\n",
    "        return x.reshape(x.size(0), -1)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: Tensor) -> Tensor:\n",
    "        (x,) = ctx.saved_tensors\n",
    "        return grad_output.reshape(x.shape)\n",
    "\n",
    "\n",
    "class CustomFlatten(nn.Module):\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return FlattenLayer.apply(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ee25e",
   "metadata": {},
   "source": [
    "### Dense Layer\n",
    "\n",
    "Der Dense Layer nimmt den flatten Feature-Vektor der vorherigen Schichten entgegen und berechnet eine affine Abbildung. Er fasst alle gelernten Merkmale zu einer kompakten Repräsentation zusammen und erzeugt letztendlich die finale RUL-Vorhersage.\n",
    "\n",
    "---\n",
    "\n",
    "#### Batch-Berechnung\n",
    "\n",
    "Forward-Pass\n",
    "\n",
    "$$X \\in \\mathbb{R}^{B \\times n},$$\n",
    "\n",
    "Gewichtsmatrix\n",
    "\n",
    "$$W \\in \\mathbb{R}^{n \\times m},$$\n",
    "\n",
    "und Bias\n",
    "\n",
    "$$b \\in \\mathbb{R}^{m}$$\n",
    "\n",
    "berechnet der Layer:\n",
    "\n",
    "$$Y = XW + b,$$\n",
    "\n",
    "wobei $b$ über die Batch-Dimension gebroadcastet wird. Die Ausgabe hat die Form\n",
    "\n",
    "$$Y \\in \\mathbb{R}^{B \\times m}.$$\n",
    "\n",
    "Jede Spalte von $W$ entspricht einem Neuron, der Layer besteht also aus $m$ Neuronen, die parallel berechnet werden.\n",
    "\n",
    "---\n",
    "\n",
    "#### Komponentenweise Darstellung\n",
    "\n",
    "Für jedes Sample $k \\in \\{1, \\dots, B\\}$ und jedes Ausgabe-Neuron $j \\in \\{1, \\dots, m\\}$:\n",
    "\n",
    "$$Y_{kj} = \\sum_{i=1}^{n} X_{ki} W_{ij} + b_j.$$\n",
    "\n",
    "---\n",
    "\n",
    "### Backward Pass (Gradienten)\n",
    "\n",
    "Sei $\\frac{\\partial \\mathcal{L}}{\\partial Y} \\in \\mathbb{R}^{B \\times m}$ der Gradient der Loss-Funktion bezüglich des Outputs. Daraus ergeben sich die Gradienten für Gewichte, Bias und Input:\n",
    "\n",
    "#### Gradient der Gewichte\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial W} = X^\\top \\cdot \\frac{\\partial \\mathcal{L}}{\\partial Y} \\quad \\in \\mathbb{R}^{n \\times m}$$\n",
    "\n",
    "#### Gradient des Bias\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial b} = \\sum_{k=1}^{B} \\frac{\\partial \\mathcal{L}}{\\partial Y}_{k} \\quad \\in \\mathbb{R}^{m}$$\n",
    "\n",
    "*(Summe über die Batch-Dimension)*\n",
    "\n",
    "#### Gradient des Inputs\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial X} = \\frac{\\partial \\mathcal{L}}{\\partial Y} \\cdot W^\\top \\quad \\in \\mathbb{R}^{B \\times n}$$\n",
    "\n",
    "---\n",
    "\n",
    "### Im Code:\n",
    "\n",
    "- `grad_weight = x.T @ grad_output` -> $\\frac{\\partial \\mathcal{L}}{\\partial W}$\n",
    "- `grad_bias = grad_output.sum(dim=0)` -> $\\frac{\\partial \\mathcal{L}}{\\partial b}$\n",
    "- `grad_x = grad_output @ weight.T` -> $\\frac{\\partial \\mathcal{L}}{\\partial X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7857fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x: Tensor, weight: Tensor, bias: Tensor) -> Tensor:\n",
    "        ctx.save_for_backward(x, weight)\n",
    "        return x @ weight + bias\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        x, weight = ctx.saved_tensors\n",
    "        grad_weight: Tensor = x.T @ grad_output\n",
    "        grad_bias: Tensor = grad_output.sum(dim=0)\n",
    "        grad_x: Tensor = grad_output @ weight.T\n",
    "        return grad_x, grad_weight, grad_bias\n",
    "\n",
    "\n",
    "class CustomDense(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int) -> None:\n",
    "        super().__init__()\n",
    "        self.weight: nn.Parameter = nn.Parameter(\n",
    "            torch.randn(in_features, out_features) * (2 / in_features) ** 0.5\n",
    "        )\n",
    "        self.bias: nn.Parameter = nn.Parameter(torch.zeros(out_features))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return DenseLayer.apply(x, self.weight, self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a302f61",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Im folgenden werden Trainings- und Testdaten geladen, normalisiert und zu Tensoren umgewandelt, sodass wir schlussendlich einen train- und test_loader haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cafa0b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     load_data,\n\u001b[32m      3\u001b[39m     normalize_data,\n\u001b[32m      4\u001b[39m     create_testing_and_training_sets,\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df_training, df_testing, new_col_names = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFILENAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m df_training_scaled, df_testing_scaled = normalize_data(\n\u001b[32m      9\u001b[39m     df_training, df_testing, new_col_names\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m train_loader, test_loader = create_testing_and_training_sets(\n\u001b[32m     12\u001b[39m     df_training_scaled, df_testing_scaled\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programmierung/algorithmen-und-verfahren/cmapps/src/data_loader.py:78\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m     74\u001b[39m X_train: np.ndarray = np.concatenate(\n\u001b[32m     75\u001b[39m     (A_dev, W_dev, X_s_dev, X_v_dev, T_dev), axis=\u001b[32m1\u001b[39m\n\u001b[32m     76\u001b[39m )\n\u001b[32m     77\u001b[39m Y_train: np.ndarray = Y_dev\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m training_set: np.ndarray = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m df_training: pd.DataFrame = pd.DataFrame(\n\u001b[32m     80\u001b[39m     data=training_set, columns=col_names\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m X_test: np.ndarray = np.concatenate(\n\u001b[32m     84\u001b[39m     (A_test, W_test, X_s_test, X_v_test, T_test), axis=\u001b[32m1\u001b[39m\n\u001b[32m     85\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programmierung/algorithmen-und-verfahren/cmapps/.venv/lib/python3.14/site-packages/numpy/_core/multiarray.py:197\u001b[39m, in \u001b[36mconcatenate\u001b[39m\u001b[34m(arrays, axis, out, dtype, casting)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[33;03m    empty_like(\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03m        prototype,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    192\u001b[39m \n\u001b[32m    193\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (prototype,)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath.concatenate)\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconcatenate\u001b[39m(arrays, axis=\u001b[32m0\u001b[39m, out=\u001b[38;5;28;01mNone\u001b[39;00m, *, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, casting=\u001b[33m\"\u001b[39m\u001b[33msame_kind\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    199\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[33;03m    concatenate(\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m        arrays,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m \n\u001b[32m    301\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# optimize for the typical case where only arrays is provided\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from src.data_loader import (\n",
    "    load_data,\n",
    "    normalize_data,\n",
    "    create_testing_and_training_sets,\n",
    ")\n",
    "\n",
    "df_training, df_testing, new_col_names = load_data(FILENAME)\n",
    "df_training_scaled, df_testing_scaled = normalize_data(\n",
    "    df_training, df_testing, new_col_names\n",
    ")\n",
    "train_loader, test_loader = create_testing_and_training_sets(\n",
    "    df_training_scaled, df_testing_scaled\n",
    ")\n",
    "\n",
    "print(f\"  Total training units:  {df_training['unit'].nunique()}\")\n",
    "print(f\"  Total test units:  {df_testing['unit'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af94c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model mit seinen Layern\n",
    "model: nn.Sequential = nn.Sequential(\n",
    "    CustomConv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    CustomLeakyReLU(),\n",
    "    CustomConv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    CustomLeakyReLU(),\n",
    "    CustomConv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    CustomLeakyReLU(),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    CustomFlatten(),\n",
    "    CustomDense(64, 64),\n",
    "    CustomLeakyReLU(),\n",
    "    CustomDense(64, 1),\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f58f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cnn import load_model\n",
    "\n",
    "# wenn LOAD_MODEL True ist, wird das Modell aus dem Checkpoint geladen,\n",
    "# ansonsten wird es mit den initialisierten Gewichten trainiert\n",
    "if LOAD_MODEL:\n",
    "    model: nn.Sequential = load_model(model, CHECKPOINT_PATH, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8afd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/20...\n",
      "  Batch 2000/82241, Avg Loss: 978.4935\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 4000/82241, Avg Loss: 790.6639\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 6000/82241, Avg Loss: 628.9881\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 8000/82241, Avg Loss: 509.6321\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 10000/82241, Avg Loss: 428.9693\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 12000/82241, Avg Loss: 373.4782\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 14000/82241, Avg Loss: 333.2076\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 16000/82241, Avg Loss: 302.6398\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 18000/82241, Avg Loss: 278.6795\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 20000/82241, Avg Loss: 259.3702\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 22000/82241, Avg Loss: 243.4425\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 24000/82241, Avg Loss: 230.0854\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 26000/82241, Avg Loss: 218.6662\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 28000/82241, Avg Loss: 208.8728\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 30000/82241, Avg Loss: 200.3248\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 32000/82241, Avg Loss: 192.7726\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 34000/82241, Avg Loss: 186.0469\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 36000/82241, Avg Loss: 180.0131\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 38000/82241, Avg Loss: 174.6455\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 40000/82241, Avg Loss: 169.7217\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 42000/82241, Avg Loss: 165.2523\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 44000/82241, Avg Loss: 161.1945\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 46000/82241, Avg Loss: 157.4234\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 48000/82241, Avg Loss: 153.9509\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 50000/82241, Avg Loss: 150.7627\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 52000/82241, Avg Loss: 147.7744\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 54000/82241, Avg Loss: 145.0042\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 56000/82241, Avg Loss: 142.4094\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 58000/82241, Avg Loss: 139.9795\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 60000/82241, Avg Loss: 137.7124\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 62000/82241, Avg Loss: 135.5680\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 64000/82241, Avg Loss: 133.5611\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 66000/82241, Avg Loss: 131.6442\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 68000/82241, Avg Loss: 129.8378\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 70000/82241, Avg Loss: 128.1170\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 72000/82241, Avg Loss: 126.4885\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 74000/82241, Avg Loss: 124.9309\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 76000/82241, Avg Loss: 123.4456\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 78000/82241, Avg Loss: 122.0197\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 80000/82241, Avg Loss: 120.6742\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 82000/82241, Avg Loss: 119.3700\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "Epoch 1/20 Complete, Train MSE=119.2152, Test MSE=112.0339\n",
      "          R2-Score: 0.6885,           Accuracy: 0.0271\n",
      "\n",
      "Starting Epoch 2/20...\n",
      "  Batch 2000/82241, Avg Loss: 66.8419\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 4000/82241, Avg Loss: 66.6817\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 6000/82241, Avg Loss: 66.4055\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 8000/82241, Avg Loss: 66.3139\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 10000/82241, Avg Loss: 66.2218\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 12000/82241, Avg Loss: 66.0950\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 14000/82241, Avg Loss: 65.9462\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 16000/82241, Avg Loss: 65.7966\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 18000/82241, Avg Loss: 65.6317\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 20000/82241, Avg Loss: 65.4698\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 22000/82241, Avg Loss: 65.3044\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 24000/82241, Avg Loss: 65.1870\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 26000/82241, Avg Loss: 65.0435\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 28000/82241, Avg Loss: 64.9144\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 30000/82241, Avg Loss: 64.7729\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 32000/82241, Avg Loss: 64.6129\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 34000/82241, Avg Loss: 64.4838\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 36000/82241, Avg Loss: 64.3718\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 38000/82241, Avg Loss: 64.2486\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 40000/82241, Avg Loss: 64.1093\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 42000/82241, Avg Loss: 63.9449\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 44000/82241, Avg Loss: 63.7931\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 46000/82241, Avg Loss: 63.6484\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 48000/82241, Avg Loss: 63.5301\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 50000/82241, Avg Loss: 63.4219\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 52000/82241, Avg Loss: 63.2752\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 54000/82241, Avg Loss: 63.1522\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 56000/82241, Avg Loss: 63.0303\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 58000/82241, Avg Loss: 62.9021\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 60000/82241, Avg Loss: 62.7832\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 62000/82241, Avg Loss: 62.6663\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 64000/82241, Avg Loss: 62.5326\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 66000/82241, Avg Loss: 62.4006\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 68000/82241, Avg Loss: 62.2646\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 70000/82241, Avg Loss: 62.1430\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 72000/82241, Avg Loss: 62.0231\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 74000/82241, Avg Loss: 61.9045\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 76000/82241, Avg Loss: 61.7829\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 78000/82241, Avg Loss: 61.6655\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 80000/82241, Avg Loss: 61.5476\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 82000/82241, Avg Loss: 61.4298\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "Epoch 2/20 Complete, Train MSE=61.4145, Test MSE=139.7334\n",
      "          R2-Score: 0.6115,           Accuracy: 0.0183\n",
      "\n",
      "Starting Epoch 3/20...\n",
      "  Batch 2000/82241, Avg Loss: 56.5602\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 4000/82241, Avg Loss: 56.4751\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 6000/82241, Avg Loss: 56.2459\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 8000/82241, Avg Loss: 56.1508\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 10000/82241, Avg Loss: 56.0489\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 12000/82241, Avg Loss: 55.9296\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 14000/82241, Avg Loss: 55.8528\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 16000/82241, Avg Loss: 55.7783\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 18000/82241, Avg Loss: 55.6968\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 20000/82241, Avg Loss: 55.5958\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 22000/82241, Avg Loss: 55.5298\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 24000/82241, Avg Loss: 55.4600\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 26000/82241, Avg Loss: 55.3725\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 28000/82241, Avg Loss: 55.2996\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 30000/82241, Avg Loss: 55.2050\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 32000/82241, Avg Loss: 55.1052\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 34000/82241, Avg Loss: 55.0009\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 36000/82241, Avg Loss: 54.8780\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 38000/82241, Avg Loss: 54.8119\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 40000/82241, Avg Loss: 54.7294\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 42000/82241, Avg Loss: 54.6443\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 44000/82241, Avg Loss: 54.5378\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 46000/82241, Avg Loss: 54.4337\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 48000/82241, Avg Loss: 54.3345\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 50000/82241, Avg Loss: 54.2411\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 52000/82241, Avg Loss: 54.1450\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 54000/82241, Avg Loss: 54.0542\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 56000/82241, Avg Loss: 53.9776\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 58000/82241, Avg Loss: 53.8846\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 60000/82241, Avg Loss: 53.7886\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 62000/82241, Avg Loss: 53.6929\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 64000/82241, Avg Loss: 53.6171\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 66000/82241, Avg Loss: 53.5205\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 68000/82241, Avg Loss: 53.4239\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 70000/82241, Avg Loss: 53.3385\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 72000/82241, Avg Loss: 53.2562\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 74000/82241, Avg Loss: 53.1763\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 76000/82241, Avg Loss: 53.0890\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 78000/82241, Avg Loss: 53.0060\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 80000/82241, Avg Loss: 52.9263\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 82000/82241, Avg Loss: 52.8434\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "Epoch 3/20 Complete, Train MSE=52.8325, Test MSE=135.7930\n",
      "          R2-Score: 0.6225,           Accuracy: 0.0382\n",
      "\n",
      "Starting Epoch 4/20...\n",
      "  Batch 2000/82241, Avg Loss: 49.7489\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 4000/82241, Avg Loss: 49.4682\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 6000/82241, Avg Loss: 49.2856\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 8000/82241, Avg Loss: 49.2682\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 10000/82241, Avg Loss: 49.2396\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 12000/82241, Avg Loss: 49.1502\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 14000/82241, Avg Loss: 49.1312\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 16000/82241, Avg Loss: 49.0408\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 18000/82241, Avg Loss: 48.9317\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 20000/82241, Avg Loss: 48.8575\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 22000/82241, Avg Loss: 48.7727\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 24000/82241, Avg Loss: 48.7105\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 26000/82241, Avg Loss: 48.6298\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 28000/82241, Avg Loss: 48.5668\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 30000/82241, Avg Loss: 48.4930\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 32000/82241, Avg Loss: 48.4113\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 34000/82241, Avg Loss: 48.3414\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 36000/82241, Avg Loss: 48.2812\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 38000/82241, Avg Loss: 48.2269\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 40000/82241, Avg Loss: 48.1605\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 42000/82241, Avg Loss: 48.1009\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 44000/82241, Avg Loss: 48.0413\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 46000/82241, Avg Loss: 47.9654\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 48000/82241, Avg Loss: 47.9002\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 50000/82241, Avg Loss: 47.8312\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 52000/82241, Avg Loss: 47.7731\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 54000/82241, Avg Loss: 47.7010\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 56000/82241, Avg Loss: 47.6393\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 58000/82241, Avg Loss: 47.5769\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 60000/82241, Avg Loss: 47.5204\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 62000/82241, Avg Loss: 47.4617\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 64000/82241, Avg Loss: 47.3961\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 66000/82241, Avg Loss: 47.3338\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 68000/82241, Avg Loss: 47.2801\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 70000/82241, Avg Loss: 47.2269\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 72000/82241, Avg Loss: 47.1648\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 74000/82241, Avg Loss: 47.1132\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 76000/82241, Avg Loss: 47.0491\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 78000/82241, Avg Loss: 46.9873\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 80000/82241, Avg Loss: 46.9356\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 82000/82241, Avg Loss: 46.8813\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "Epoch 4/20 Complete, Train MSE=46.8728, Test MSE=105.3922\n",
      "          R2-Score: 0.7070,           Accuracy: 0.0427\n",
      "\n",
      "Starting Epoch 5/20...\n",
      "  Batch 2000/82241, Avg Loss: 44.1237\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 4000/82241, Avg Loss: 44.2546\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 6000/82241, Avg Loss: 44.2034\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 8000/82241, Avg Loss: 44.1981\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 10000/82241, Avg Loss: 44.1740\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 12000/82241, Avg Loss: 44.1683\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 14000/82241, Avg Loss: 44.1071\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 16000/82241, Avg Loss: 44.0277\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 18000/82241, Avg Loss: 44.0104\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 20000/82241, Avg Loss: 43.9642\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 22000/82241, Avg Loss: 43.9195\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 24000/82241, Avg Loss: 43.8932\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 26000/82241, Avg Loss: 43.8295\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 28000/82241, Avg Loss: 43.7861\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 30000/82241, Avg Loss: 43.7524\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 32000/82241, Avg Loss: 43.7093\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 34000/82241, Avg Loss: 43.6766\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 36000/82241, Avg Loss: 43.6419\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 38000/82241, Avg Loss: 43.5745\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 40000/82241, Avg Loss: 43.5133\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 42000/82241, Avg Loss: 43.4586\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 44000/82241, Avg Loss: 43.4077\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 46000/82241, Avg Loss: 43.3642\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 48000/82241, Avg Loss: 43.3279\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 50000/82241, Avg Loss: 43.2969\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 52000/82241, Avg Loss: 43.2578\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 54000/82241, Avg Loss: 43.2202\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 56000/82241, Avg Loss: 43.1802\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 58000/82241, Avg Loss: 43.1210\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 60000/82241, Avg Loss: 43.0876\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 62000/82241, Avg Loss: 43.0450\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 64000/82241, Avg Loss: 42.9867\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 66000/82241, Avg Loss: 42.9363\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 68000/82241, Avg Loss: 42.8892\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 70000/82241, Avg Loss: 42.8508\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 72000/82241, Avg Loss: 42.8080\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 74000/82241, Avg Loss: 42.7678\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 76000/82241, Avg Loss: 42.7318\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 78000/82241, Avg Loss: 42.6910\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 80000/82241, Avg Loss: 42.6422\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 82000/82241, Avg Loss: 42.6010\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "Epoch 5/20 Complete, Train MSE=42.5955, Test MSE=196.6552\n",
      "          R2-Score: 0.4533,           Accuracy: 0.0341\n",
      "\n",
      "Starting Epoch 6/20...\n",
      "  Batch 2000/82241, Avg Loss: 41.3626\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 4000/82241, Avg Loss: 41.1629\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 6000/82241, Avg Loss: 40.9836\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 8000/82241, Avg Loss: 40.8911\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 10000/82241, Avg Loss: 40.7964\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 12000/82241, Avg Loss: 40.7097\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 14000/82241, Avg Loss: 40.6906\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 16000/82241, Avg Loss: 40.6642\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 18000/82241, Avg Loss: 40.6428\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 20000/82241, Avg Loss: 40.6152\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 22000/82241, Avg Loss: 40.5553\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 24000/82241, Avg Loss: 40.5022\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 26000/82241, Avg Loss: 40.4657\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 28000/82241, Avg Loss: 40.4298\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 30000/82241, Avg Loss: 40.4029\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 32000/82241, Avg Loss: 40.3598\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 34000/82241, Avg Loss: 40.3355\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 36000/82241, Avg Loss: 40.2896\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 38000/82241, Avg Loss: 40.2575\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 40000/82241, Avg Loss: 40.2020\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 42000/82241, Avg Loss: 40.1611\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 44000/82241, Avg Loss: 40.1306\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 46000/82241, Avg Loss: 40.0948\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 48000/82241, Avg Loss: 40.0622\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 50000/82241, Avg Loss: 40.0228\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 52000/82241, Avg Loss: 39.9971\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 54000/82241, Avg Loss: 39.9645\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 56000/82241, Avg Loss: 39.9263\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 58000/82241, Avg Loss: 39.9020\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 60000/82241, Avg Loss: 39.8823\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 62000/82241, Avg Loss: 39.8417\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 64000/82241, Avg Loss: 39.8145\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n",
      "  Batch 66000/82241, Avg Loss: 39.7828\n",
      "  Autosaved to network_checkpoint_dataset_two.pth\n"
     ]
    }
   ],
   "source": [
    "from src.cnn import evaluate_test_loss, mse_torch\n",
    "\n",
    "# setzen des Optimizers sowie der Lernrate\n",
    "optimizer: torch.optim.Adam = torch.optim.Adam(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "total_loss: list[Tensor] = []\n",
    "total_test_loss: list[Tensor] = []\n",
    "CHECKPOINT_PATH_SAVE: str = \"network_checkpoint_dataset_two.pth\"\n",
    "autosave = 2000\n",
    "epochs: int = 20\n",
    "for e in range(epochs):\n",
    "    # model auf Trainingsmodus setzen\n",
    "    model.train()\n",
    "    error: float = 0.0\n",
    "    num_batches: int = 0\n",
    "    # previous_loss: float = 0.0\n",
    "    print(f\"Starting Epoch {e + 1}/{epochs}...\")\n",
    "\n",
    "    # durch die Batches des Trainingsloaders iterieren\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Daten auf das richtige Device verschieben und die Dimensionen anpassen\n",
    "        X_batch: Tensor = X_batch.to(DEVICE).unsqueeze(1)  # (B, 1, 10, 36)\n",
    "        y_batch: Tensor = y_batch.to(DEVICE).view(-1, 1)\n",
    "\n",
    "        # Gradienten zurücksetzen\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward Pass\n",
    "        output: Tensor = model(X_batch)\n",
    "\n",
    "        # Überprüfen auf NaN-Werte im Output, da dies bereits einmal ein Fehler war\n",
    "        if torch.isnan(output).any():\n",
    "            print(f\"NaN detected in output at batch {num_batches}!\")\n",
    "            break\n",
    "\n",
    "        # Cost- / Loss-Funktion\n",
    "        loss: Tensor = mse_torch(y_batch, output)\n",
    "\n",
    "        # L2-Regularisierung\n",
    "        # l2_lambda: float = 1e-4\n",
    "        # l2_norm = 0.0\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.requires_grad and \"bias\" not in name:\n",
    "        #         l2_norm += torch.sum(param.pow(2))\n",
    "\n",
    "        # loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "        # Backward Pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update der Gewichte\n",
    "        optimizer.step()\n",
    "\n",
    "        error += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        # Model Autosave\n",
    "        if num_batches % autosave == 0:\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": e,\n",
    "                    \"batch_idx\": num_batches,\n",
    "                    \"batch_size\": BATCH_SIZE,\n",
    "                    \"learning_rate\": LEARNING_RATE,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                },\n",
    "                CHECKPOINT_PATH_SAVE,\n",
    "            )\n",
    "            print(\n",
    "                f\"  Batch {num_batches}/{len(train_loader)}, Avg Loss: {error / num_batches:.4f}\"\n",
    "            )\n",
    "            print(f\"  Autosaved to {CHECKPOINT_PATH_SAVE}\")\n",
    "            total_loss.append(error / num_batches)\n",
    "            # test_loss, test_r2, test_accuracy = evaluate_test_loss(model, DEVICE, test_loader)\n",
    "            # total_test_loss.append(test_loss)\n",
    "\n",
    "        # Abbruchbedingung: starke Konvergenz der Verlustfunktion\n",
    "        # if abs(loss.item() - previous_loss) < 1e-3:\n",
    "        #     print(f\"  Loss change below threshold at batch {num_batches}, stopping early.\")\n",
    "        #     break\n",
    "        previous_loss = loss.item()\n",
    "\n",
    "    if loss:\n",
    "        total_loss.append(loss.item())\n",
    "    error /= max(num_batches, 1)\n",
    "    test_loss, test_r2, test_accuracy = evaluate_test_loss(\n",
    "        model, DEVICE, test_loader\n",
    "    )\n",
    "    total_test_loss.append(test_loss)\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {e + 1}/{epochs} Complete, Train MSE={error:.4f}, Test MSE={test_loss:.4f}\\n\\\n",
    "          R2-Score: {test_r2:.4f}, \\\n",
    "          Accuracy: {test_accuracy:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6409b1d",
   "metadata": {},
   "source": [
    "## Plotting of a unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb600b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from src.cnn import load_model\n",
    "\n",
    "# model laden\n",
    "model = load_model(model, CHECKPOINT_PATH, DEVICE)\n",
    "# Unit zum Plotten auswählen\n",
    "test_unit_no = 7\n",
    "\n",
    "# Daten für die ausgewählte Unit extrahieren\n",
    "unit_data = df_testing_scaled[df_testing_scaled[\"unit\"] == test_unit_no]\n",
    "unit_data_raw = df_testing[\n",
    "    df_testing[\"unit\"] == test_unit_no\n",
    "]  # unscaled, for real cycle numbers\n",
    "\n",
    "# Für Forward Pass\n",
    "X_test_unit: list[Tensor] = []\n",
    "y_test_unit: list[Tensor] = []\n",
    "# Für x-Achse im Plotten (echte Zyklenzahl, nicht skaliert)\n",
    "cycles_test_unit: list[int] = []\n",
    "\n",
    "# Erstellen von Testdaten im Window-Format für die ausgewählte Unit\n",
    "for i in range(0, len(unit_data) - WIN_LEN + 1):\n",
    "    temp = unit_data.iloc[i : i + WIN_LEN]  # skaliert, für die Vorhersage\n",
    "    temp_raw = unit_data_raw.iloc[\n",
    "        i : i + WIN_LEN\n",
    "    ]  # unskaliert, für die echten Zyklenzahlen\n",
    "    x_temp = temp.drop(columns=[\"unit\", \"RUL\"]).values\n",
    "    y_temp = temp[\"RUL\"].values[-1]\n",
    "    X_test_unit.append(x_temp)\n",
    "    y_test_unit.append(y_temp)\n",
    "    cycles_test_unit.append(temp_raw[\"cycle\"].values[-1])\n",
    "\n",
    "X_test_tensor: Tensor = torch.tensor(X_test_unit, dtype=torch.float32)\n",
    "dataset: TensorDataset = TensorDataset(X_test_tensor)\n",
    "loader: DataLoader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "predictions: list[Tensor] = []\n",
    "# forward pass, ohne Gradientenberechnung, da nur Predictions berechnet werden\n",
    "with torch.no_grad():\n",
    "    for (batch,) in loader:\n",
    "        batch = batch.to(DEVICE).unsqueeze(1)  # (B, 1, 10, 36)\n",
    "        batch_pred = model(batch)\n",
    "        predictions.append(batch_pred.cpu())\n",
    "\n",
    "# Predictions zusammenfügen, in numpy-Array umwandeln und flatten\n",
    "y_pred = torch.cat(predictions).numpy().flatten()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cycles_test_unit, y_test_unit, label=\"True RUL\", marker=\"o\")\n",
    "plt.plot(cycles_test_unit, y_pred, label=\"Predicted RUL\", marker=\"x\")\n",
    "plt.title(f\"True vs Predicted RUL (Unit {test_unit_no})\")\n",
    "plt.xlabel(\"Cycle\")\n",
    "plt.ylabel(\"RUL\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd82fc09",
   "metadata": {},
   "source": [
    "## Interactive RUL Prediction Demo\n",
    "\n",
    "Wähle eine Triebwerkseinheit und ziehe den Slider, um festzulegen, wie viele Zyklen an Daten bekannt sein sollen. Die rote gestrichelte Linie markiert den aktuellen Zeitpunkt – alles links davon sind beobachtete Daten, und die Vorhersage zeigt, was das Modell zu diesem Zeitpunkt ausgeben würde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83b560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Pre-computing predictions for all units…\n",
      "==================================================\n",
      "[1/4] Processing unit 7… 392585 rows → 392576 windows… done. RUL [0–89]\n",
      "[2/4] Processing unit 8… 800294 rows → 800285 windows… done. RUL [0–88]\n",
      "[3/4] Processing unit 9… 351683 rows → 351674 windows… done. RUL [0–79]\n",
      "[4/4] Processing unit 10… 1190670 rows → 1190661 windows… done. RUL [0–81]\n",
      "==================================================\n",
      "✓ All 4 units cached. Widgets are ready.\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26580fc265243b380f4763622cc7b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Engine Unit:', layout=Layout(width='300px'), options=(7, 8…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from src.cnn import load_model\n",
    "\n",
    "model = load_model(model, CHECKPOINT_PATH, DEVICE)\n",
    "\n",
    "# Data Loading\n",
    "print(\"=\" * 50)\n",
    "print(\"Pre-computing predictions for all units…\")\n",
    "print(\"=\" * 50, flush=True)\n",
    "\n",
    "unit_cache: dict[int, dict[str, np.ndarray]] = {}\n",
    "available_units: list[int] = sorted(\n",
    "    df_testing[\"unit\"].unique().astype(int).tolist()\n",
    ")\n",
    "total_units: int = len(available_units)\n",
    "\n",
    "for idx_u, unit_no in enumerate(available_units, start=1):\n",
    "    print(\n",
    "        f\"[{idx_u}/{total_units}] Processing unit {unit_no}…\",\n",
    "        end=\" \",\n",
    "        flush=True,\n",
    "    )\n",
    "\n",
    "    unit_scaled: pd.DataFrame = df_testing_scaled[\n",
    "        df_testing_scaled[\"unit\"] == unit_no\n",
    "    ].reset_index(drop=True)\n",
    "    unit_raw: pd.DataFrame = df_testing[\n",
    "        df_testing[\"unit\"] == unit_no\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    if len(unit_scaled) < WIN_LEN:\n",
    "        unit_cache[unit_no] = {\"cycles\": [], \"y_true\": [], \"y_pred\": []}\n",
    "        print(\"skipped (not enough cycles).\", flush=True)\n",
    "        continue\n",
    "\n",
    "    n: int = len(unit_scaled)\n",
    "    feat_cols: list[str] = [\n",
    "        c for c in unit_scaled.columns if c not in (\"unit\", \"RUL\")\n",
    "    ]\n",
    "    X_arr: np.ndarray = unit_scaled[feat_cols].values\n",
    "\n",
    "    print(f\"{n} rows -> {n - WIN_LEN + 1} windows…\", end=\" \", flush=True)\n",
    "\n",
    "    X_windows: np.ndarray = np.stack(\n",
    "        [X_arr[i : i + WIN_LEN] for i in range(n - WIN_LEN + 1)]\n",
    "    )\n",
    "\n",
    "    y_true_list, cycles_list = [], []\n",
    "    for i in range(n - WIN_LEN + 1):\n",
    "        y_true_list.append(unit_scaled[\"RUL\"].values[i + WIN_LEN - 1])\n",
    "        cycles_list.append(unit_raw[\"cycle\"].values[i + WIN_LEN - 1])\n",
    "    y_true_arr: np.ndarray = np.array(y_true_list)\n",
    "    cycles_arr = np.array(cycles_list)\n",
    "\n",
    "    X_tensor: Tensor = torch.tensor(X_windows, dtype=torch.float32)\n",
    "    loader: DataLoader = DataLoader(\n",
    "        TensorDataset(X_tensor), batch_size=256, shuffle=False\n",
    "    )\n",
    "\n",
    "    preds: list[Tensor] = []\n",
    "    with torch.no_grad():\n",
    "        for (batch,) in loader:\n",
    "            preds.append(model(batch.to(DEVICE).unsqueeze(1)).cpu())\n",
    "\n",
    "    y_pred_arr: np.ndarray = torch.cat(preds).numpy().flatten()\n",
    "\n",
    "    unit_cache[unit_no]: dict[str, np.ndarray] = {\n",
    "        \"cycles\": cycles_arr,\n",
    "        \"y_true\": y_true_arr,\n",
    "        \"y_pred\": y_pred_arr,\n",
    "    }\n",
    "\n",
    "    rul_range = f\"RUL [{y_true_arr.min():.0f}–{y_true_arr.max():.0f}]\"\n",
    "    print(f\"done. {rul_range}\", flush=True)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"All {total_units} units cached. Widgets are ready.\")\n",
    "print(\"=\" * 50, flush=True)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "def plot_agent(unit_no: int, cycle_cutoff: int) -> None:\n",
    "    cache: dict[str, np.ndarray] = unit_cache[unit_no]\n",
    "    cycles: np.ndarray = np.array(cache[\"cycles\"])\n",
    "    y_true: np.ndarray = np.array(cache[\"y_true\"])\n",
    "    y_pred: np.ndarray = np.array(cache[\"y_pred\"])\n",
    "\n",
    "    if len(cycles) == 0:\n",
    "        print(f\"Unit {unit_no}: not enough cycles.\")\n",
    "        return\n",
    "\n",
    "    # Observed: all windows whose last cycle <= cutoff\n",
    "    mask_obs: np.ndarray = cycles <= cycle_cutoff\n",
    "\n",
    "    if not mask_obs.any():\n",
    "        print(f\"Unit {unit_no}: no observed windows at cycle {cycle_cutoff}.\")\n",
    "        return\n",
    "\n",
    "    obs_cycles: np.ndarray = cycles[mask_obs]\n",
    "    obs_true: np.ndarray = y_true[mask_obs]\n",
    "    obs_pred: np.ndarray = y_pred[mask_obs]\n",
    "\n",
    "    # Forecast: windows AFTER cutoff — model already saw these during caching\n",
    "    mask_fore: np.ndarray = cycles > cycle_cutoff\n",
    "    fore_cycles: np.ndarray = cycles[mask_fore]\n",
    "    fore_pred: np.ndarray = y_pred[mask_fore]\n",
    "\n",
    "    # RUL at cutoff = last predicted value in observed window\n",
    "    rul_at_cutoff: float = obs_pred[-1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(13, 5))\n",
    "\n",
    "    # True RUL (solid blue)\n",
    "    ax.plot(\n",
    "        obs_cycles,\n",
    "        obs_true,\n",
    "        color=\"steelblue\",\n",
    "        linewidth=1.8,\n",
    "        marker=\"o\",\n",
    "        markersize=2.5,\n",
    "        label=\"True RUL (observed)\",\n",
    "    )\n",
    "\n",
    "    # Predicted RUL in observed range (solid orange)\n",
    "    ax.plot(\n",
    "        obs_cycles,\n",
    "        obs_pred,\n",
    "        color=\"darkorange\",\n",
    "        linewidth=1.5,\n",
    "        marker=\"x\",\n",
    "        markersize=2.5,\n",
    "        label=\"Predicted RUL (observed)\",\n",
    "    )\n",
    "\n",
    "    # Forecast: connect smoothly from last observed pred into future (dashed)\n",
    "    if mask_fore.any():\n",
    "        # Prepend the last observed point so the dashed line starts without a gap\n",
    "        fore_cycles_full: np.ndarray = np.concatenate(\n",
    "            [[obs_cycles[-1]], fore_cycles]\n",
    "        )\n",
    "        fore_pred_full: np.ndarray = np.concatenate(\n",
    "            [[rul_at_cutoff], fore_pred]\n",
    "        )\n",
    "        ax.plot(\n",
    "            fore_cycles_full,\n",
    "            fore_pred_full,\n",
    "            color=\"darkorange\",\n",
    "            linewidth=2.0,\n",
    "            linestyle=\"--\",\n",
    "            marker=\"\",\n",
    "            label=\"Predicted RUL (forecast)\",\n",
    "        )\n",
    "\n",
    "    # Cutoff line\n",
    "    ax.axvline(\n",
    "        cycle_cutoff,\n",
    "        color=\"crimson\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2.0,\n",
    "        label=f\"Now — cycle {cycle_cutoff}\",\n",
    "    )\n",
    "\n",
    "    # RUL annotation\n",
    "    ax.annotate(\n",
    "        f\"  RUL ≈ {rul_at_cutoff:.0f} cycles\",\n",
    "        xy=(cycle_cutoff, rul_at_cutoff),\n",
    "        xytext=(\n",
    "            cycle_cutoff + (cycles.max() - cycles.min()) * 0.03,\n",
    "            rul_at_cutoff,\n",
    "        ),\n",
    "        fontsize=11,\n",
    "        color=\"crimson\",\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"crimson\", lw=1.2),\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"RUL Prediction  |  Unit {unit_no}  |  Observed up to cycle {cycle_cutoff}\",\n",
    "        fontsize=13,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax.set_xlabel(\"Cycle\", fontsize=11)\n",
    "    ax.set_ylabel(\"RUL (cycles remaining)\", fontsize=11)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.35)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Widgets\n",
    "max_cycle: int = int(df_testing[\"cycle\"].max())\n",
    "\n",
    "unit_widget: widgets.Dropdown = widgets.Dropdown(\n",
    "    options=available_units,\n",
    "    value=available_units[0],\n",
    "    description=\"Engine Unit:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=widgets.Layout(width=\"300px\"),\n",
    ")\n",
    "\n",
    "cycle_widget: widgets.IntSlider = widgets.IntSlider(\n",
    "    min=WIN_LEN,\n",
    "    max=max_cycle,\n",
    "    step=1,\n",
    "    value=50,\n",
    "    description=\"Current cycle:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=widgets.Layout(width=\"600px\"),\n",
    "    continuous_update=False,\n",
    ")\n",
    "\n",
    "out: widgets.interactive = widgets.interactive_output(\n",
    "    plot_agent, {\"unit_no\": unit_widget, \"cycle_cutoff\": cycle_widget}\n",
    ")\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([unit_widget]), cycle_widget, out]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmapps (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
